{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom CNN\n",
    "\n",
    "We'll go over:\n",
    "\n",
    "* Prepping input\n",
    "* Sequential model\n",
    "* Training the model\n",
    "* Saving the model\n",
    "* Saving the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.1.0\n",
      "Keras version: 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "print(\"Keras version:\", tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Input\n",
    "\n",
    "We need to define the following:\n",
    "\n",
    "* input shape\n",
    "* training data generator\n",
    "* validation data generator\n",
    "\n",
    "Most CNN's depend on a static input size in this example our input will be 160 x 160\n",
    "\n",
    "Also make sure to notice that we are rescaling the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (160, 160, 3)\n",
    "\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are creating our training and validation data generators\n",
    "\n",
    "This should be super simple as long as all of your images are structured correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12897 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'imagenette-160/train',\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    target_size=(160, 160)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    'imagenette-160/val',\n",
    "    shuffle=False,\n",
    "    class_mode='categorical',\n",
    "    target_size=(160, 160)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Model\n",
    "\n",
    "There are generally two types of model in the keras library, `Sequential` and `Functional`\n",
    "\n",
    "The `Sequential` on is easier to instantiate but less flexible when creating the model structure\n",
    "\n",
    "We'll go over `Functional` models in a later tutorial\n",
    "\n",
    "### Layers\n",
    "\n",
    "* Conv2D - Essentially it is just dragging some number of filters M that are of size N x N across the image\n",
    "* Activation - This is basically always a relu until the final layer a relu is a type of non-linearity\n",
    "* MaxPooling2D - This will downsample your image taking the highest number out of a N x N filter\n",
    "* Dropout - Helps regularize your network, basically it helps with overfitting, all nodes will have an X chance of dropping out\n",
    "* Flatten - This layer will take our 2D network and collapse it down to 1D\n",
    "* This will add a fully connected layer this is usually done right before the final layer\n",
    "\n",
    "If these terms confuse you, checkout this playlist from Stanford on Convolutional Neural Networks:\n",
    "\n",
    "[Link to playlist](https://www.youtube.com/watch?v=ArPaAX_PhIs&list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF)\n",
    "\n",
    "#### Note on the final layer\n",
    "\n",
    "The final layer uses a `softmax` finction for classification you can use the following table as guideline for your final layer:\n",
    "\n",
    "| Problem type                            | Last-layer activation | Lost function              |\n",
    "|-----------------------------------------|-----------------------|----------------------------|\n",
    "| Binary classification                   | sigmoid               | binary_crossentropy        |\n",
    "| Multiclass, single-label classification | softmax               | categorical_crossentropy   |\n",
    "| Multiclass, multiclass classification   | sigmoid               | binary_crossentropy        |\n",
    "| Regression to arbitrary values          | None                  | mse                        |\n",
    "| Regression to values between 0 and 1    | sigmoid               | mse or binary_crossentropy |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# first layer always needs input shape but after that it's unecessary\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# notice how the architecture repeats but just adds more filters this is a common scheme used in CNNs\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a summary of our model with the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 160, 160, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 160, 160, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 158, 158, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 158, 158, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 79, 79, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 79, 79, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 79, 79, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 79, 79, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 77, 77, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 77, 77, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 92416)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               47317504  \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 47,388,202\n",
      "Trainable params: 47,388,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model\n",
    "\n",
    "* choose and optimizer\n",
    "* choose a loss function\n",
    "* define some metrics to monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use RMSProp as our optimizer\n",
    "opt = RMSprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "               optimizer=opt,\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model\n",
    "\n",
    "Here we actually 'fit' or 'train' the model\n",
    "\n",
    "We need to pass the following:\n",
    "\n",
    "* training generator (defined in the beginning)\n",
    "* number of epochs (times you pass through the data)\n",
    "* validation generator (defined in the beginning)\n",
    "\n",
    "The best accuracy I was able to achieve without data augmentation was about %72 you can see the biggest jumps between the first 3 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 202 steps, validate for 16 steps\n",
      "Epoch 1/3\n",
      "202/202 [==============================] - 19s 95ms/step - loss: 0.8218 - accuracy: 0.7388 - val_loss: 0.9120 - val_accuracy: 0.7040\n",
      "Epoch 2/3\n",
      "202/202 [==============================] - 19s 96ms/step - loss: 0.6054 - accuracy: 0.8049 - val_loss: 0.9318 - val_accuracy: 0.6960\n",
      "Epoch 3/3\n",
      "202/202 [==============================] - 19s 95ms/step - loss: 0.4375 - accuracy: 0.8611 - val_loss: 1.1009 - val_accuracy: 0.7140\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    epochs=3,\n",
    "    validation_data=valid_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving your Model\n",
    "\n",
    "below we will save both the model itself and the weights used to train it, later we'll show cases where we'll need one or the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the most common way to save your model is the following\n",
    "model.save('models/custom_model.h5')\n",
    "model.save_weights('models/custom_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case you need it as a json\n",
    "with open('models/custom_architecture.json', 'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot your model\n",
    "\n",
    "You can plot your model to an image to see a rough outline of the graph (we'll view this in tensorboard later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file='plots/models/custom_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need\n",
    "# sudo apt-get install graphviz\n",
    "# conda install pydot\n",
    "# conda install pydotplus\n",
    "# TODO get all packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
